{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFVKqwl0lcqB"
   },
   "source": [
    "## Step 4: Configuring training\n",
    "\n",
    "Now that the data is ready it's time to create a training configuration. In this notebook I'm making use of EfficientDet, but you can replace it with any model available in the [Tensorflow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('models/research/object_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "do_gTIvOmYLz"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_steps = 80000\n",
    "num_eval_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "NpjBFLBTmgJx",
    "outputId": "dd91ec12-f3fa-476f-d1d1-2ecabe64f96d"
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4T9FnPUzmkb6"
   },
   "outputs": [],
   "source": [
    "fine_tune_checkpoint = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "CqUvMcj_mnTK",
    "outputId": "c4481a5d-6483-425f-f2d3-c4e721494e70"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\n",
    "print(os.getcwd())\n",
    "\n",
    "base_config_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap_path = 'ASL_data/classes.pbtxt'\n",
    "train_record_path = 'ASL_data/train.record'\n",
    "valid_record_path = 'ASL_data/test.record'\n",
    "test_record_path = 'ASL_data/valid.record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJKGl6lunUaK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(base_config_path) as f:\n",
    "    config = f.read()\n",
    "\n",
    "with open('model_config.config', 'w') as f:\n",
    "  \n",
    "  # Set labelmap path\n",
    "  config = re.sub('label_map_path: \".*?\"', \n",
    "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
    "  \n",
    "  # Set fine_tune_checkpoint path\n",
    "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
    "  \n",
    "  # Set train tf-record file path\n",
    "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
    "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
    "  \n",
    "  # Set test tf-record file path\n",
    "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
    "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
    "  \n",
    "  # Set number of classes.\n",
    "  config = re.sub('num_classes: [0-9]+',\n",
    "                  'num_classes: {}'.format(35), config)\n",
    "  \n",
    "  # Set batch size\n",
    "  config = re.sub('batch_size: [0-9]+',\n",
    "                  'batch_size: {}'.format(batch_size), config)\n",
    "  \n",
    "  # Set training steps\n",
    "  config = re.sub('num_steps: [0-9]+',\n",
    "                  'num_steps: {}'.format(num_steps), config)\n",
    "  \n",
    "  # Set fine-tune checkpoint type to detection\n",
    "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
    "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
    "  \n",
    "  f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat model_config.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "SYa-Rid6rz15",
    "outputId": "f5184e83-24d7-49fd-9a10-020968e61f85"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "pipeline_config_path = 'model_config.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrceQxPOr8vv"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!whereis cudnn.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!whereis nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MhI6B_8ZsnJs",
    "outputId": "b99406f2-0184-4b78-faf7-0cd5aebd1c18"
   },
   "outputs": [],
   "source": [
    "!python model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_config_path} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "h1wZp2WUAKSU",
    "outputId": "e7b59c04-3e96-4f04-c63f-13fdf86ae748"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'training/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2nwyos8AhwN"
   },
   "source": [
    "### Export model inference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "GkDNB4vbATb4",
    "outputId": "176a0a21-2fae-4073-9ee2-5d38a28ada44"
   },
   "outputs": [],
   "source": [
    "output_directory = 'inference_graph'\n",
    "print(model_dir)\n",
    "print(output_directory)\n",
    "print(pipeline_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "kKYeERSXA2re",
    "outputId": "1a641e03-7c2a-4190-cefa-e06c1ca975f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {model_dir} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_config_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH6OPq1qDt-3"
   },
   "source": [
    "## Step 5: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvFjcSyYA8_l"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import six\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from six import BytesIO\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6tB7pyiBFiN"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: a file path (this can be local or on colossus)\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXXRIgD_CBf4"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zbVBMcpUCElG",
    "outputId": "c5c45ef0-5ca8-4a91-f052-323947ceb9d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infer():\n",
    "    os.chdir('models/research/object_detection')\n",
    "    output_directory = 'inference_graph'\n",
    "    labelmap_path = 'ASL_data/classes.pbtxt'\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.saved_model.load(f'{output_directory}/saved_model')\n",
    "    print(model)\n",
    "    with open('ASL_data/test.txt') as f:\n",
    "        for line in f:\n",
    "\n",
    "            image_path = str(line.rstrip())\n",
    "            image_np = load_image_into_numpy_array(image_path)\n",
    "            output_dict = run_inference_for_single_image(model, image_np)\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              output_dict['detection_boxes'],\n",
    "              output_dict['detection_classes'],\n",
    "              output_dict['detection_scores'],\n",
    "              category_index,\n",
    "              instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=8)\n",
    "            display(Image.fromarray(image_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Process(target=infer)\n",
    "p.start()\n",
    "p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ObjectDetectionPipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
